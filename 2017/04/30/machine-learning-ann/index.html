<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Machine Learning - Artificial Neural Network | 夏日小草</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning - Artificial Neural Network">
<meta property="og:url" content="http://homeway.me/2017/04/30/machine-learning-ann/index.html">
<meta property="og:site_name" content="夏日小草">
<meta property="og:image" content="https://static.blog.homeway.me/blog/machine-learning-logox.png">
<meta property="og:image" content="https://static.blog.homeway.me/blog/2017-04-30-neuron.png">
<meta property="og:image" content="https://static.blog.homeway.me/blog/2017-04-30-sgn-function.png">
<meta property="og:image" content="https://static.blog.homeway.me/blog/2017-04-30-squashing-function.png">
<meta property="og:image" content="https://static.blog.homeway.me/blog/2017-04-30-neural-networks-working.png">
<meta property="og:image" content="https://static.blog.homeway.me/blog/2017-04-30-multilayer-perceptron.png">
<meta property="og:image" content="https://static.blog.homeway.me/blog/2017-04-30-global-minimum-local-minimum.png">
<meta property="og:image" content="https://static.blog.homeway.me/blog/2017-04-30-basic-neural-network-unit-neuron.png">
<meta property="og:image" content="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-1.png">
<meta property="og:image" content="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-3.png">
<meta property="og:image" content="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-4.png">
<meta property="og:image" content="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-5.png">
<meta property="og:image" content="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-6.png">
<meta property="og:image" content="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-7.png">
<meta property="og:image" content="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-8.png">
<meta property="og:image" content="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-9.png">
<meta property="og:image" content="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-10.png">
<meta property="og:image" content="https://static.blog.homeway.me/blog/2017-04-30-ann-cross-validation.jpg">
<meta property="og:updated_time" content="2018-10-21T16:37:36.531Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine Learning - Artificial Neural Network">
<meta name="twitter:image" content="https://static.blog.homeway.me/blog/machine-learning-logox.png">
<meta name="twitter:creator" content="@xiarixiaocao">
<link rel="publisher" href="yaohomeway">
  
    <link rel="alternative" href="/atom.xml" title="夏日小草" type="application/atom+xml">
  
  
    <link rel="icon" href="http://77l5jp.com1.z0.glb.clouddn.com/blog%2Fgithub-ico.png">
  
  <link rel="stylesheet" href="https://static.blog.homeway.me/blog/style.min.css?v=1602255192" type="text/css">
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  <!-- 评论模块 -->
  <link rel="stylesheet" href="http://comment.blog.seclab.org.cn/css/static.css">  
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-54364570-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics --><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">夏日小草</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">念念不忘 必有回响</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/atom.xml">Rss</a>
        
          <a class="main-nav-link" href="/music/">Music</a>
        
          <a class="main-nav-link" href="/about/">About</a>
        

<!-- High一下 -->
<a class="main-nav-link" href='javascript:(function() {
  function c() {
    var e = document.createElement("link");
    e.setAttribute("type", "text/css");
    e.setAttribute("rel", "stylesheet");
    e.setAttribute("href", f);
    e.setAttribute("class", l);
    document.body.appendChild(e)
  }
  function h() {
    var e = document.getElementsByClassName(l);
    for (var t = 0; t < e.length; t++) {
      document.body.removeChild(e[t])
    }
  }
  function p() {
    var e = document.createElement("div");
    e.setAttribute("class", a);
    document.body.appendChild(e);
    setTimeout(function() {
      document.body.removeChild(e)
    }, 100)
  }
  function d(e) {
    return {
      height : e.offsetHeight,
      width : e.offsetWidth
    }
  }
  function v(i) {
    var s = d(i);
    return s.height > e && s.height < n && s.width > t && s.width < r
  }
  function m(e) {
    var t = e;
    var n = 0;
    while (!!t) {
      n += t.offsetTop;
      t = t.offsetParent
    }
    return n
  }
  function g() {
    var e = document.documentElement;
    if (!!window.innerWidth) {
      return window.innerHeight
    } else if (e && !isNaN(e.clientHeight)) {
      return e.clientHeight
    }
    return 0
  }
  function y() {
    if (window.pageYOffset) {
      return window.pageYOffset
    }
    return Math.max(document.documentElement.scrollTop, document.body.scrollTop)
  }
  function E(e) {
    var t = m(e);
    return t >= w && t <= b + w
  }
  function S() {
    var e = document.createElement("audio");
    e.setAttribute("class", l);
    e.src = i;
    e.loop = false;
    e.addEventListener("canplay", function() {
      setTimeout(function() {
        x(k)
      }, 500);
      setTimeout(function() {
        N();
        p();
        for (var e = 0; e < O.length; e++) {
          T(O[e])
        }
      }, 7000)
    }, true);
    e.addEventListener("ended", function() {
      N();
      h()
    }, true);
    e.innerHTML = " <p>If you are reading this, it is because your browser does not support the audio element. We recommend that you get a new browser.</p> <p>";
    document.body.appendChild(e);
    e.play()
  }
  function x(e) {
    e.className += " " + s + " " + o
  }
  function T(e) {
    e.className += " " + s + " " + u[Math.floor(Math.random() * u.length)]
  }
  function N() {
    var e = document.getElementsByClassName(s);
    var t = new RegExp("\\b" + s + "\\b");
    for (var n = 0; n < e.length; ) {
      e[n].className = e[n].className.replace(t, "")
    }
  }
  var e = 30;
  var t = 30;
  var n = 450;
  var r = 450;
  var i = "//xiaocao.u.qiniudn.com/music/harlem-shake.mp3";
  var s = "mw-harlem_shake_me";
  var o = "im_first";
  var u = ["im_drunk", "im_baked", "im_trippin", "im_blown"];
  var a = "mw-strobe_light";
  var f = "//xiaocao.u.qiniudn.com/css/harlem-shake-style.min.css";
  var l = "mw_added_css";
  var b = g();
  var w = y();
  var C = document.getElementsByTagName("*");
  var k = null;
  for (var L = 0; L < C.length; L++) {
    var A = C[L];
    if (v(A)) {
      if (E(A)) {
        k = A;
        break
      }
    }
  }
  if (A === null) {
    console.warn("Could not find a node of the right size. Please try a different page.");
    return
  }
  c();
  S();
  var O = [];
  for (var L = 0; L < C.length; L++) {
    var A = C[L];
    if (v(A)) {
      O.push(A)
    }
  }
})()'>开心一下~~~</a>
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="http://www.baidu.com/baidu" method="get" accept-charset="utf-8" class="search-form">
          <input type="search" name="word" maxlength="20" class="search-form-input" placeholder="Search">
          <input type="submit" value="" class="search-form-submit">
          <input name=tn type=hidden value="bds">
          <input name=cl type=hidden value="3">
          <input name=ct type=hidden value="2097152">
          <input type="hidden" name="si" value="homeway.me">
        </form>
      </div>
    </div>
  </div>
</header>

<!--
<div id="site_search" class="main-content-wrap">
<input type="text" id="local-search-input" name="q" results="0" placeholder="search" class="form-control input--xlarge" autofocus="autofocus"/>
<div id="local-search-result"></div>
-->
      <div class="outer">
        <section id="main"><article id="post-machine-learning-ann" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/04/30/machine-learning-ann/" class="article-date">
  <time datetime="2017-04-30T14:02:10.000Z" itemprop="datePublished">4月 30 2017</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Machine Learning - Artificial Neural Network
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><br></p>
<p><img src="https://static.blog.homeway.me/blog/machine-learning-logox.png" alt="Machine Learning"></p>
<a id="more"></a>
<h1 id="About"><a href="#About" class="headerlink" title="About"></a>About</h1><p>Artifical Neural Network(ANN) which is inspired by human brain neural, provide a general, practical method for learning real-valued, discrete-valued, and vector-valued functions from examples. Artifical Neural Network algorithm such as Backpropagation use gradient descent to tune network parameters to best fit a training set of input-outputpairs.</p>
<p><hr><br></p>
<h1 id="How-to-work"><a href="#How-to-work" class="headerlink" title="How to work"></a>How to work</h1><h2 id="1-Neuron"><a href="#1-Neuron" class="headerlink" title="1.Neuron"></a>1.Neuron</h2><p><img src="https://static.blog.homeway.me/blog/2017-04-30-neuron.png" alt="Figue 1: Artificial Neural Network (picture from 《机器学习-周志华》)"></p>
<p>The basic component of an ANN network is node unit called neuron. These neurons connect with pre-neurons with bridges in different weights. Every neuron receive signal from bridges and evaluated by activation function to output. In ideal situation, activation function is like figue 2, input value from pre-neuron and return 0 or 1:</p>
<p><img src="https://static.blog.homeway.me/blog/2017-04-30-sgn-function.png" alt="Figue 2: Output in ideal situation"></p>
<p>Besides the logistic function, sigmoid functions include the ordinary arctangent, the hyperbolic tangent, the Gudermannian function, and the error function, but also the generalised logistic function and algebraic functions(Figue 3):</p>
<p><img src="https://static.blog.homeway.me/blog/2017-04-30-squashing-function.png" alt="Figue 3: Some sigmoid functions: In the drawing all functions are normalized in such a way &lt;br&gt;that their slope at the origin is like figue 2.(picture from wikipedia)"></p>
<h2 id="2-Multilayer-perceptron"><a href="#2-Multilayer-perceptron" class="headerlink" title="2.Multilayer perceptron"></a>2.Multilayer perceptron</h2><p>An ANN network consists at least a input, output layer and hidden layer in which consists multilayer perceptron(MLP), which is a feedforward artificial neural network model that maps sets of input data onto a set of appropriate outputs. </p>
<p><img src="https://static.blog.homeway.me/blog/2017-04-30-neural-networks-working.png" alt="Figue 4: Multilayer perceptron module"></p>
<p>A single perceptron can be used to represent many boolean functions(such as AND/OR/NOT). For example:</p>
<blockquote>
<p>AND (X1 ^ X2): Suppose w1 = w2 = 1, θ = 2, X0(bias) = 0, and y = f(1 · X1 + 1 · X2 - 2), then only when X1 = X2 = 1, y = 1<br>OR (X1 v X2): Suppose w1 = w2 = 1, θ = 0.5, X0(bias) = 0, and y = f(1 · X1 + 1 · X2 - 0.5), then only when X1 = 1 or X2 = 1, y = 1<br>NOT (!X1): Suppose w1 = 1, w2 = 0, θ = -0.5, X0(bias) = 0, and y = f(1 · X1 + 0 · X2 + 0.5), when X1 =  1, y = 0; X1 = 0, y = 1</p>
</blockquote>
<p>Unfortunately, however, some boolean func- tions cannot be represented by a single perceptron, such as the XOR function whose value is 1 if and only if x1 ≠ x2. Note the set of linearly nonseparable training examples shown in figure 5 corresponds to this XOR function:</p>
<p><img src="https://static.blog.homeway.me/blog/2017-04-30-multilayer-perceptron.png" alt="Figue 5: AND/OR/XOR/NOT boolearn function(picture from 《机器学习-周志华》)"></p>
<p>The ability of perceptrons to represent AND, OR, AND, and NOR is important because every boolean function can be represented by some network of interconnected units based on these primitives. In fact, every boolean function can be represented by some network of perceptrons only two levels deep, in which the inputs are fed to multiple units, and the outputs of these units are then input to a second, final stage. One way is to represent the boolean function in disjunctive normal form (i.e., as the disjunction (OR) of a set of conjunctions (ANDs) of the inputs and their negations). Note that the input to an AND perceptron can be negated simply by changing the sign of the corresponding input weight.</p>
<h2 id="3-Gradient-descent"><a href="#3-Gradient-descent" class="headerlink" title="3.Gradient descent"></a>3.Gradient descent</h2><p>Gradient descent is a first-order iterative optimization algorithm. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or of the approximate gradient) of the function at the current point. (From: <a href="https://en.wikipedia.org/wiki/Gradient_descent#Description" target="_blank" rel="external">https://en.wikipedia.org/wiki/Gradient_descent#Description</a>).</p>
<p><img src="https://static.blog.homeway.me/blog/2017-04-30-global-minimum-local-minimum.png" alt="Figue 6: global minimum and local minmum (picture from 《机器学习-周志华》)"></p>
<p>To sum, we may use gradient descent to approach the minimum for a formula. And from gradient descent we may get local minimum and global minimum, but how could we check whether the data I caculate is global minimum but local minimum?(<a href="http://stackoverflow.com/questions/9163801/gradient-descent-implementation" target="_blank" rel="external">http://stackoverflow.com/questions/9163801/gradient-descent-implementation</a>)</p>
<ul>
<li>Add noise. This reduces the precision of the parameters you’ve found, which can “blur” out local minima. The search can then jump out of local minima that are small compared to the noise, while still being trapped in deeper minima. A well-known approach for adding noise is simulated annealing.</li>
<li>Add momentum. Along with using the current gradient to define the step, also continue in the same direction as the previous step. If you take a fraction of the previous step as the momentum term, there is a tendency to keep going, which can take the search past the local minimum. By using a fraction, the steps decay exponentially, so poor steps aren’t a big problem. This was always a popular modification to gradient descent when used to train neural networks, where gradient descent is known as backpropagation.</li>
<li>Use a hybrid search. First use a global search (e.g., genetic algorithms, various Monte Carlo methods) to find some good starting points, then apply gradient descent to take advantage of the gradient information in the function.</li>
</ul>
<h2 id="4-BackPropagation"><a href="#4-BackPropagation" class="headerlink" title="4.BackPropagation"></a>4.BackPropagation</h2><p>The backward propagation of errors, or backpropagation, is a common method of training artificial neural networks and used in conjunction with an optimization method such as gradient descent. <a href="https://en.wikipedia.org/wiki/Backpropagation" target="_blank" rel="external">Backpropagatio wiki: https://en.wikipedia.org/wiki/Backpropagation</a></p>
<p>The BackPropagation follows two steps: </p>
<ul>
<li><p>step 1: Propagation</p>
<ul>
<li>Forward propagation of a training pattern’s input through the neural network in order to generate the propagation’s output activations.</li>
<li>Backward propagation of the propagation’s output activations through the neural network using the training pattern target in order to generate the deltas of all output and hidden neurons.</li>
</ul>
</li>
<li><p>step 2: Weight update</p>
<ul>
<li>Multiply its output delta and input activation to get the gradient of the weight.</li>
<li>Subtract a ratio (percentage) of the gradient from the weight.     </li>
</ul>
</li>
</ul>
<p><img src="https://static.blog.homeway.me/blog/2017-04-30-basic-neural-network-unit-neuron.png" alt="Figue 7: BackPropagation alogrithm"></p>
<p>Step one is caculate nodes output by giving weight, bias, squashing function, then get output node value; Step two needs to correcte predict value and target value, then return an error check value, which using gradient descent algorithm to feed-forward the weights.</p>
<p><img src="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-1.png" alt="Formula 1: Neuron node sum"></p>
<p>Let`s return to the case of a single neuron N with weights W = (w0, … , wn) and an input X = (x1, x2 … xn), as is shown at Formula 1. And momentarily, let us add the activation function from Figue 3. </p>
<p>Supposing we predict output value as Yj, and f(x) as sigmoid function, the output may be this:</p>
<p><img src="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-3.png" alt="Formula 2: Neuron node predict value"></p>
<p>where θ is the bias of node, and as return of Formula 1 for simple. Now after processing, we may get all output values, so it is easy to get prediction square error:</p>
<p><img src="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-4.png" alt="Formula 3: Neuron prediction square error"></p>
<p>For convenience we add a factor of 1/2 to real E and drop the subscript N from f(N). Since minimizing E is the same as minimizing 0.5 * E, this changes nothing about the minima of the function. </p>
<p>Note that E is never negative, and so it will have a global minimum value at or near 0 (if it is possible for the neuron to represent the target function perfectly, it will be zero). That is, our update rule should be:</p>
<p><img src="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-5.png" alt="Formula 4: weight update rule"></p>
<p>where η is some fixed parameter between 0 and 1 that represent the “learning rate.”, δE is prediction square error. We will not mention η too much except to say that as long as it is sufficiently small and we allow ourselves enough time to learn, we are guaranteed to get a good approximation of some local minimum (though it might not be a global one).</p>
<p>And further, consider BackPropagation algotithm is base on <a href="http://homeway.me/2017/04/30/machine-learning-ann/#Gradient descent">Gradient descent</a>, we need seeking guidance for E:</p>
<p><img src="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-6.png" alt="Formula 5: seeking guidance for E"></p>
<p>Due to the continuity of the neural network, we can split the Formula 5 for:</p>
<p><img src="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-7.png" alt="Formula 6: split the appeal formula"></p>
<p>Here, we found sigmoid f(x) = 1 / (1 + np.exp(-x)), has a good attribute, which can be described:</p>
<p><img src="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-8.png" alt="Formula 7: sigmoid function&#39;s useful attribute"></p>
<p>Finally, we may base on Formula 5/6/7, return a new formula:</p>
<p><img src="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-9.png" alt="Formula 8: combine formula 5/6/7"></p>
<p>And now we can get the new weight formula:</p>
<p><img src="http://oorkttmj2.bkt.clouddn.com/blog/ml/2017-04-30-ann-formula-10.png" alt="Formula 9: new weight formula"></p>
<h2 id="5-Cross-Validation"><a href="#5-Cross-Validation" class="headerlink" title="5.Cross Validation"></a>5.Cross Validation</h2><p>www.cs.cmu.edu’s slider “Overfitting, Cross-Validation”: <a href="http://www.cs.cmu.edu/~guestrin/Class/10701-S05/slides/NNet-CrossValidation-2-2-2005.pdf" target="_blank" rel="external">http://www.cs.cmu.edu/~guestrin/Class/10701-S05/slides/NNet-CrossValidation-2-2-2005.pdf</a></p>
<p>Cross-validation, sometimes called rotation estimation, is a model validation technique for assessing how the results of a statistical analysis will generalize to an independent data set, which can easily described by Figue 8:</p>
<p><img src="https://static.blog.homeway.me/blog/2017-04-30-ann-cross-validation.jpg" alt="Figue 8: Cross Validation"></p>
<p>For Figue 8, we may choose different groups data and finally caculate their average, more information is avaiable in wikipedia: <a href="https://en.wikipedia.org/wiki/Cross-validation" target="_blank" rel="external">https://en.wikipedia.org/wiki/Cross-validation</a> </p>
<p><hr><br></p>
<h1 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h1><p>Github code: <a href="https://github.com/grasses/Machine-Learning/blob/master/dl/NeuralNetworks/nn.py" target="_blank" rel="external">https://github.com/grasses/Machine-Learning/blob/master/dl/NeuralNetworks/nn.py</a></p>
<pre><code>import numpy as np

class NeuralNetwork(object):
    &#39;&#39;&#39;
    :param layers: A list containing the number of units in each layer. Should be at least two values.
    :param activation: The activation function to be used. Can be &quot;logistic&quot; or &quot;tanh&quot;.
    &#39;&#39;&#39;
    def __init__(self, layers, activation = &#39;tanh&#39;):
        if activation == &#39;logistic&#39;:
            self.activation = self.logistic
            self.activation_deriv = self.logistic_derivative
        elif activation == &#39;tanh&#39;:
            self.activation = self.tanh
            self.activation_deriv = self.tanh_deriv
        &#39;&#39;&#39;
        generate weight matrix with random float
        &#39;&#39;&#39;
        self.weights = []
        for i in range(1, len(layers) - 1):
            self.weights.append((2 * np.random.random((layers[i - 1] + 1, layers[i] + 1)) - 1) * 0.25)
            self.weights.append((2 * np.random.random((layers[i] + 1, layers[i + 1])) - 1) * 0.25)

    @staticmethod
    def tanh(x):
        return np.tanh(x)

    @staticmethod
    def tanh_deriv(x):
        return 1.0 - np.tanh(x) * np.tanh(x)

    @staticmethod
    def logistic(x):
        return 1 / (1 + np.exp(-x))

    @staticmethod
    def logistic_derivative(x):
        return NeuralNetwork.logistic(x) * (1 - NeuralNetwork.logistic(x))

    &#39;&#39;&#39;
    :param X        numpy.array     train matrix
    :param y        numpy.array     result label
    :param learning_rate    float
    :param epochs   int             backprobagation times
    &#39;&#39;&#39;
    def fit(self, X, y, learning_rate = 0.2, epochs = 10000):
        X = np.atleast_2d(X)
        temp = np.ones([X.shape[0], X.shape[1] + 1])
        temp[:, 0:-1] = X
        X = temp
        y = np.array(y)

        &#39;&#39;&#39;
        loop operation for epochs times
        &#39;&#39;&#39;
        for k in range(epochs):
            # select a random line from X for training
            i = np.random.randint(X.shape[0])
            a = [X[i]]

            # going forward network, for each layer
            for l in range(len(self.weights)):
                # computer the node value for each layer (O_i) using activation function
                a.append(self.activation(np.dot(a[l], self.weights[l])))
            # computer the error at the top layer
            error = y[i] - a[-1]
            deltas = [
                error * self.activation_deriv(a[-1])]  # For output layer, Err calculation (delta is updated error)

            # start backprobagation
            for l in range(len(a) - 2, 0, -1):  # we need to begin at the second to last layer
                # compute the updated error (i,e, deltas) for each node going from top layer to input layer
                deltas.append(deltas[-1].dot(self.weights[l].T) * self.activation_deriv(a[l]))
            deltas.reverse()
            for i in range(len(self.weights)):
                layer = np.atleast_2d(a[i])
                delta = np.atleast_2d(deltas[i])
                self.weights[i] += learning_rate * layer.T.dot(delta)

    def predict(self, x):
        x = np.array(x)
        temp = np.ones(x.shape[0] + 1)
        temp[0:-1] = x
        a = temp
        for l in range(0, len(self.weights)):
            a = self.activation(np.dot(a, self.weights[l]))
        return a
</code></pre><p><hr><br></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>*《机器学习-周志华》<a href="https://www.amazon.cn/%E5%9B%BE%E4%B9%A6/dp/B01ARKEV1G/" target="_blank" rel="external">https://www.amazon.cn/图书/dp/B01ARKEV1G/</a></p>
<ul>
<li>Wikipedia Artificial Neural Network: <a href="https://en.wikipedia.org/wiki/Artificial_neural_network" target="_blank" rel="external">https://en.wikipedia.org/wiki/Artificial_neural_network</a></li>
<li>Wikipedia Gradient Descent: <a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank" rel="external">https://en.wikipedia.org/wiki/Gradient_descent</a></li>
<li>Artificial Neural Network (ANN) - Introduction: <a href="http://www.bogotobogo.com/python/scikit-learn/Artificial-Neural-Network-ANN-1-Introduction.php" target="_blank" rel="external">http://www.bogotobogo.com</a></li>
<li>Neural Networks and the Backpropagation Algorithm:<a href="https://jeremykun.com/2012/12/09/neural-networks-and-backpropagation/" target="_blank" rel="external">https://jeremykun.com/2012/12/09/neural-networks-and-backpropagation/</a></li>
</ul>
<!--neural-networks-working.png

-blog/2017-04-30-sigmoid-function.png
-->
<p><hr><br></p>
<h4 id="本文出自-夏日小草-转载请注明出处-http-homeway-me-2017-04-30-machine-learning-ann"><a href="#本文出自-夏日小草-转载请注明出处-http-homeway-me-2017-04-30-machine-learning-ann" class="headerlink" title="本文出自 夏日小草,转载请注明出处:http://homeway.me/2017/04/30/machine-learning-ann/"></a>本文出自 <a href="http://homeway.me">夏日小草</a>,转载请注明出处:<a href="http://homeway.me/2017/04/30/machine-learning-ann/">http://homeway.me/2017/04/30/machine-learning-ann/</a></h4><p>-by grasses</p>
<p>2017-04-30 16:52:34</p>

      
    </div>
    
    <footer class="article-footer">
      <a data-url="http://homeway.me/2017/04/30/machine-learning-ann/" data-id="cjo8cqb31005rrdolpujsu5mb" data-title="Machine Learning - Artificial Neural Network" class="article-share-link">Share</a>
      <!--  -->
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>

  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/05/04/pattern-writer-identify/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Pattern - writter identify using texture descriptors
        
      </div>
    </a>
  
  
    <a href="/2017/04/21/machine-learning-knn/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Machine Learning - K-Nearest Neighbor</div>
    </a>
  
</nav>

  
</article>


<!--评论模块-->

  <section id="comments">
    <div id="comments"></div>
  </section>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Coding/">Coding</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Environment/">Environment</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Life/">Life</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Summary/">Summary</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tech/">Tech</a><span class="category-list-count">40</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Work/">Work</a><span class="category-list-count">6</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Android/" style="font-size: 11.67px;">Android</a> <a href="/tags/Arduino/" style="font-size: 11.67px;">Arduino</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/HTTP/" style="font-size: 11.67px;">HTTP</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Life/" style="font-size: 11.67px;">Life</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Mac/" style="font-size: 10px;">Mac</a> <a href="/tags/Machine-Learning/" style="font-size: 16.67px;">Machine Learning</a> <a href="/tags/Moogodb/" style="font-size: 10px;">Moogodb</a> <a href="/tags/Mysql/" style="font-size: 13.33px;">Mysql</a> <a href="/tags/Nginx/" style="font-size: 20px;">Nginx</a> <a href="/tags/Nodejs/" style="font-size: 10px;">Nodejs</a> <a href="/tags/OS/" style="font-size: 10px;">OS</a> <a href="/tags/Oauth/" style="font-size: 11.67px;">Oauth</a> <a href="/tags/OpenWRT/" style="font-size: 10px;">OpenWRT</a> <a href="/tags/PHP/" style="font-size: 15px;">PHP</a> <a href="/tags/Python/" style="font-size: 16.67px;">Python</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/Summary/" style="font-size: 11.67px;">Summary</a> <a href="/tags/Typecho/" style="font-size: 10px;">Typecho</a> <a href="/tags/Web/" style="font-size: 11.67px;">Web</a> <a href="/tags/树莓派/" style="font-size: 18.33px;">树莓派</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/08/05/tamper-detection-an-overview/">Forged Image Detection and Location</a>
          </li>
        
          <li>
            <a href="/2018/01/25/setup-caffe-for-deep-learning/">Deep Learning - Installing Caffe on Ubuntu</a>
          </li>
        
          <li>
            <a href="/2017/08/08/setup-gpu-for-tensorflow/">Deep Learning - Setup GPU for tensorflow</a>
          </li>
        
          <li>
            <a href="/2017/05/22/machine-learning-naive-bayesian/">Machine Learning - Naive Bayesian theory</a>
          </li>
        
          <li>
            <a href="/2017/05/04/pattern-writer-identify/">Pattern - writter identify using texture descriptors</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Links</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="http://xiaocaoblog.diandian.com" target="_blank">Old-Blog-diandian</a>
          </li>
        
          <li>
            <a href="http://blog.segmentfault.com/xiaocao" target="_blank">Old-Blog-SF</a>
          </li>
        
          <li>
            <a href="http://www.php101.cn/" target="_blank">PHP101(土豆丫)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
  	<!-- weibo加载慢，放在footer部分 -->
    <h3 id="weibo-widget-title" class="widget-title"></h3>
    <div id="weibo-widget-content" class="widget"></div>
  </div>

  
</aside>
        
      </div>
      <script>
// 微博加载最慢，放最后
title = 'Weibo';
content = '<iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=1&ptype=1&speed=0&skin=2&isTitle=1&noborder=1&isWeibo=1&isFans=1&uid=1964206997&verifier=b9041467&dpc=1"></iframe>';
(document.getElementById('weibo-widget-title')).innerHTML += title;
(document.getElementById('weibo-widget-content')).innerHTML += content;
</script>

<footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 grasses <a href="http://www.miibeian.gov.cn/" target="_blank"> 浙ICP备14012013号-2 </a>, 浙公安备 2284262 号<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/xiangming/landscape-plus" target="_blank">Landscape+</a>
    </div>
  </div>
</footer>

<a target="_blank" href="https://github.com/grasses"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://static.blog.homeway.me/blog/logo-github.png" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_white_ffffff.png"></a>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/atom.xml" class="mobile-nav-link">Rss</a>
  
    <a href="/music/" class="mobile-nav-link">Music</a>
  
    <a href="/about/" class="mobile-nav-link">About</a>
  
</nav>
    <script src="https://static.blog.homeway.me/blog/jquery.2.1.1.js"></script>


<!--七牛静态文件加速-->
<link rel="stylesheet" href="https://static.blog.homeway.me/blog/jquery.fancybox.css" media="screen" type="text/css">
<script src="https://static.blog.homeway.me/blog/jquery.fancybox.js"></script>


<!--highlight-->
<link rel="stylesheet" href="//cdn.bootcss.com/highlight.js/9.8.0/styles/atom-one-dark.min.css">
<script src="//cdn.bootcss.com/highlight.js/9.9.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!--
<script>
var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        success: function( xmlResponse ) {
            // get the contents from search data
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            if (!$input) return;
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var str='<ul class=\"search-result-list\">';                
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length <= 0) {
                    return;
                }
                // perform local searching
                var numOfPostFound = 0; // keeping track of # of result
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {//&& data_content != ''
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        numOfPostFound += 1; // keeping track of # of results
                        str += "<li style='color:white;'><a style='color:white;' href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        /*
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 100;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substr(start, end); 
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<em class=\"search-keyword\">"+keyword+"</em>");
                            });
                            
                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        */
                        str += "</li>";
                    }
                });
                str += "</ul>";
                // attaching a summary of searching result
                if (numOfPostFound > 0) {
                    if (numOfPostFound > 1) {
                        summary = numOfPostFound + " posts found";
                    } else {
                        summary = numOfPostFound + " post found";
                    }
                } else {
                    summary = "Nothing found";
                }
                var summary = "<p class=\"text-xlarge text-color-base archieve-result search-result-summary\">" + summary + "</ul>";
                $resultContent.innerHTML = summary + str;
                console.log($resultContent);
            });
        }
    });
}
     var search_path = "search.xml";
     if (search_path.length == 0) {
      search_path = "search.xml";
     }
     var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
</script>
-->

<script src="http://comment.blog.seclab.org.cn/js/static.js"></script>
<script>
LaraDuoshuo.APP_KEY = 'base64:x8zNmv3JSS79l7S9YgPB1MO4drZJ5HIUmOu1VDN9hUA=';
LaraDuoshuo.BaseURL = 'http://comment.blog.seclab.org.cn';
</script>


<!--七牛静态文件加速-->
<script src="https://static.blog.homeway.me/blog/jquery.qrcode.js"></script>
<script src="https://static.blog.homeway.me/blog/qrcode.js"></script>
<script src="https://static.blog.homeway.me/blog/script.js"></script>

  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="http://static.blog.homeway.me/blog/js/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>